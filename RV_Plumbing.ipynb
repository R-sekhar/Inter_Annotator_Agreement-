{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60068e57-f7d5-48f0-868e-f279b85aa507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Agreement Metrics:\n",
      "  Overall Agreement (row-level): 0.64\n",
      "  Accuracy: 0.64\n",
      "  Precision: 0.73\n",
      "  Recall: 0.74\n",
      "  F1 Score: 0.74\n",
      "Comparison results saved to: 'Results/A1 VS A2_RV_Plumbing.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Read Annotator Data ---\n",
    "# Replace these file names with your actual Excel file names.\n",
    "df_a1 = pd.read_excel('Annotator1_plumbing.xlsx')\n",
    "df_a2 = pd.read_excel('Annotator2_plumbing.xlsx')\n",
    "\n",
    "# --- Step 1.1: Clean Column Names ---\n",
    "df_a1.columns = df_a1.columns.str.strip()\n",
    "df_a2.columns = df_a2.columns.str.strip()\n",
    "\n",
    "# --- Step 1.2: Rename Columns if Needed ---\n",
    "# For Annotator 1:\n",
    "if 'Argument' not in df_a1.columns and 'Arguments' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Arguments': 'Argument'}, inplace=True)\n",
    "if 'Argument2' not in df_a1.columns and 'Arguments2' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Arguments2': 'Argument2'}, inplace=True)\n",
    "if 'Sense' not in df_a1.columns and 'Senses' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Senses': 'Sense'}, inplace=True)\n",
    "if 'Sense2' not in df_a1.columns and 'Senses2' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Senses2': 'Sense2'}, inplace=True)\n",
    "\n",
    "# For Annotator 2:\n",
    "if 'Argument' not in df_a2.columns and 'Arguments' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Arguments': 'Argument'}, inplace=True)\n",
    "if 'Argument2' not in df_a2.columns and 'Arguments2' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Arguments2': 'Argument2'}, inplace=True)\n",
    "if 'Sense' not in df_a2.columns and 'Senses' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Senses': 'Sense'}, inplace=True)\n",
    "if 'Sense2' not in df_a2.columns and 'Senses2' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Senses2': 'Sense2'}, inplace=True)\n",
    "\n",
    "# --- Step 1.3: (Optional) Preserve Order from Annotator1 ---\n",
    "df_a1['order'] = df_a1.index\n",
    "\n",
    "# --- Step 2: Reshape Each Annotator's Data to Long Format ---\n",
    "df_a1_long = pd.DataFrame({\n",
    "    \"Argument\": pd.concat([df_a1[\"Argument\"], df_a1[\"Argument2\"]], ignore_index=True),\n",
    "    \"Sense_a1\": pd.concat([df_a1[\"Sense\"], df_a1[\"Sense2\"]], ignore_index=True)\n",
    "})\n",
    "df_a2_long = pd.DataFrame({\n",
    "    \"Argument\": pd.concat([df_a2[\"Argument\"], df_a2[\"Argument2\"]], ignore_index=True),\n",
    "    \"Sense_a2\": pd.concat([df_a2[\"Sense\"], df_a2[\"Sense2\"]], ignore_index=True)\n",
    "})\n",
    "\n",
    "# --- Step 2.1: Remove blank or missing Argument entries before merging ---\n",
    "df_a1_long = df_a1_long[df_a1_long[\"Argument\"].notna() & df_a1_long[\"Argument\"].str.strip().ne(\"\")]\n",
    "df_a2_long = df_a2_long[df_a2_long[\"Argument\"].notna() & df_a2_long[\"Argument\"].str.strip().ne(\"\")]\n",
    "\n",
    "# --- Step 3: Merge the Two Long DataFrames on \"Argument\" ---\n",
    "merged_df = pd.merge(df_a1_long, df_a2_long, on=\"Argument\", how=\"outer\", sort=False)\n",
    "\n",
    "# --- Step 4: Process Missing Values ---\n",
    "merged_df[\"Sense_a1\"] = merged_df[\"Sense_a1\"].fillna(\"N/A\")\n",
    "merged_df[\"Sense_a2\"] = merged_df[\"Sense_a2\"].fillna(\"N/A\")\n",
    "\n",
    "# Remove rows where both annotations are \"N/A\"\n",
    "merged_df = merged_df[~((merged_df[\"Sense_a1\"] == \"N/A\") & (merged_df[\"Sense_a2\"] == \"N/A\"))]\n",
    "\n",
    "# --- Step 5: Compute Row-Level Agreement ---\n",
    "def compute_agreement(row):\n",
    "    s1 = row[\"Sense_a1\"].lower().strip()\n",
    "    s2 = row[\"Sense_a2\"].lower().strip()\n",
    "    if s1 == \"n/a\" or s2 == \"n/a\":\n",
    "        return 0\n",
    "    return 1 if s1 == s2 else 0\n",
    "\n",
    "merged_df[\"Agreement\"] = merged_df.apply(compute_agreement, axis=1)\n",
    "\n",
    "# --- Step 6: Compute Global Metrics ---\n",
    "A1_inter_A2 = merged_df['Agreement'].sum()\n",
    "A1_union_A2 = len(merged_df)\n",
    "accuracy = A1_inter_A2 / A1_union_A2 if A1_union_A2 > 0 else 0\n",
    "\n",
    "precision = A1_inter_A2 / merged_df[merged_df['Sense_a1'] != \"N/A\"].shape[0] if merged_df['Sense_a1'].ne(\"N/A\").any() else 0\n",
    "recall = A1_inter_A2 / merged_df[merged_df['Sense_a2'] != \"N/A\"].shape[0] if merged_df['Sense_a2'].ne(\"N/A\").any() else 0\n",
    "f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# --- Step 7: Print Results ---\n",
    "print(\"Global Agreement Metrics:\")\n",
    "print(f\"  Overall Agreement (row-level): {merged_df['Agreement'].mean():.2f}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}\")\n",
    "print(f\"  Precision: {precision:.2f}\")\n",
    "print(f\"  Recall: {recall:.2f}\")\n",
    "print(f\"  F1 Score: {f1:.2f}\")\n",
    "\n",
    "# --- Step 8: Save the Final Merged Comparison to Excel ---\n",
    "output_filename = \"Results/A1 VS A2_RV_Plumbing.xlsx\"\n",
    "merged_df.to_excel(output_filename, index=False)\n",
    "print(f\"Comparison results saved to: '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9082b5-2c39-4d43-a43a-50b552e0497c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Agreement Metrics:\n",
      "  Overall Agreement (row-level): 0.94\n",
      "  Accuracy: 0.94\n",
      "  Precision: 0.96\n",
      "  Recall: 0.96\n",
      "  F1 Score: 0.96\n",
      "Comparison results saved to: 'Results/A1 VS FINAL_RV_Plumbing.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Read Annotator Data ---\n",
    "# Replace these file names with your actual Excel file names.\n",
    "df_a1 = pd.read_excel('Annotator1_plumbing.xlsx')\n",
    "df_a2 = pd.read_excel('Final Annotation of RV Plumbing.xlsx')\n",
    "\n",
    "# --- Step 1.1: Clean Column Names ---\n",
    "df_a1.columns = df_a1.columns.str.strip()\n",
    "df_a2.columns = df_a2.columns.str.strip()\n",
    "\n",
    "# --- Step 1.2: Rename Columns if Needed ---\n",
    "# For Annotator 1:\n",
    "if 'Argument' not in df_a1.columns and 'Arguments' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Arguments': 'Argument'}, inplace=True)\n",
    "if 'Argument2' not in df_a1.columns and 'Arguments2' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Arguments2': 'Argument2'}, inplace=True)\n",
    "if 'Sense' not in df_a1.columns and 'Senses' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Senses': 'Sense'}, inplace=True)\n",
    "if 'Sense2' not in df_a1.columns and 'Senses2' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Senses2': 'Sense2'}, inplace=True)\n",
    "\n",
    "# For Annotator 2:\n",
    "if 'Argument' not in df_a2.columns and 'Arguments' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Arguments': 'Argument'}, inplace=True)\n",
    "if 'Argument2' not in df_a2.columns and 'Arguments2' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Arguments2': 'Argument2'}, inplace=True)\n",
    "if 'Sense' not in df_a2.columns and 'Senses' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Senses': 'Sense'}, inplace=True)\n",
    "if 'Sense2' not in df_a2.columns and 'Senses2' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Senses2': 'Sense2'}, inplace=True)\n",
    "\n",
    "# --- Step 1.3: (Optional) Preserve Order from Annotator1 ---\n",
    "df_a1['order'] = df_a1.index\n",
    "\n",
    "# --- Step 2: Reshape Each Annotator's Data to Long Format ---\n",
    "df_a1_long = pd.DataFrame({\n",
    "    \"Argument\": pd.concat([df_a1[\"Argument\"], df_a1[\"Argument2\"]], ignore_index=True),\n",
    "    \"Sense_a1\": pd.concat([df_a1[\"Sense\"], df_a1[\"Sense2\"]], ignore_index=True)\n",
    "})\n",
    "df_a2_long = pd.DataFrame({\n",
    "    \"Argument\": pd.concat([df_a2[\"Argument\"], df_a2[\"Argument2\"]], ignore_index=True),\n",
    "    \"Sense_a2\": pd.concat([df_a2[\"Sense\"], df_a2[\"Sense2\"]], ignore_index=True)\n",
    "})\n",
    "\n",
    "# --- Step 2.1: Remove blank or missing Argument entries before merging ---\n",
    "df_a1_long = df_a1_long[df_a1_long[\"Argument\"].notna() & df_a1_long[\"Argument\"].str.strip().ne(\"\")]\n",
    "df_a2_long = df_a2_long[df_a2_long[\"Argument\"].notna() & df_a2_long[\"Argument\"].str.strip().ne(\"\")]\n",
    "\n",
    "# --- Step 3: Merge the Two Long DataFrames on \"Argument\" ---\n",
    "merged_df = pd.merge(df_a1_long, df_a2_long, on=\"Argument\", how=\"outer\", sort=False)\n",
    "\n",
    "# --- Step 4: Process Missing Values ---\n",
    "merged_df[\"Sense_a1\"] = merged_df[\"Sense_a1\"].fillna(\"N/A\")\n",
    "merged_df[\"Sense_a2\"] = merged_df[\"Sense_a2\"].fillna(\"N/A\")\n",
    "\n",
    "# Remove rows where both annotations are \"N/A\"\n",
    "merged_df = merged_df[~((merged_df[\"Sense_a1\"] == \"N/A\") & (merged_df[\"Sense_a2\"] == \"N/A\"))]\n",
    "\n",
    "# --- Step 5: Compute Row-Level Agreement ---\n",
    "def compute_agreement(row):\n",
    "    s1 = row[\"Sense_a1\"].lower().strip()\n",
    "    s2 = row[\"Sense_a2\"].lower().strip()\n",
    "    if s1 == \"n/a\" or s2 == \"n/a\":\n",
    "        return 0\n",
    "    return 1 if s1 == s2 else 0\n",
    "\n",
    "merged_df[\"Agreement\"] = merged_df.apply(compute_agreement, axis=1)\n",
    "\n",
    "# --- Step 6: Compute Global Metrics ---\n",
    "A1_inter_A2 = merged_df['Agreement'].sum()\n",
    "A1_union_A2 = len(merged_df)\n",
    "accuracy = A1_inter_A2 / A1_union_A2 if A1_union_A2 > 0 else 0\n",
    "\n",
    "precision = A1_inter_A2 / merged_df[merged_df['Sense_a1'] != \"N/A\"].shape[0] if merged_df['Sense_a1'].ne(\"N/A\").any() else 0\n",
    "recall = A1_inter_A2 / merged_df[merged_df['Sense_a2'] != \"N/A\"].shape[0] if merged_df['Sense_a2'].ne(\"N/A\").any() else 0\n",
    "f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# --- Step 7: Print Results ---\n",
    "print(\"Global Agreement Metrics:\")\n",
    "print(f\"  Overall Agreement (row-level): {merged_df['Agreement'].mean():.2f}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}\")\n",
    "print(f\"  Precision: {precision:.2f}\")\n",
    "print(f\"  Recall: {recall:.2f}\")\n",
    "print(f\"  F1 Score: {f1:.2f}\")\n",
    "\n",
    "# --- Step 8: Save the Final Merged Comparison to Excel ---\n",
    "output_filename = \"Results/A1 VS FINAL_RV_Plumbing.xlsx\"\n",
    "merged_df.to_excel(output_filename, index=False)\n",
    "print(f\"Comparison results saved to: '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f739ab-f881-497e-9924-615a8ae953b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Agreement Metrics:\n",
      "  Overall Agreement (row-level): 0.67\n",
      "  Accuracy: 0.67\n",
      "  Precision: 0.76\n",
      "  Recall: 0.75\n",
      "  F1 Score: 0.75\n",
      "Comparison results saved to: 'Results/A2 VS FINAL_RV_Plumbing.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Read Annotator Data ---\n",
    "# Replace these file names with your actual Excel file names.\n",
    "df_a1 = pd.read_excel('Annotator2_plumbing.xlsx')\n",
    "df_a2 = pd.read_excel('Final Annotation of RV Plumbing.xlsx')\n",
    "\n",
    "# --- Step 1.1: Clean Column Names ---\n",
    "df_a1.columns = df_a1.columns.str.strip()\n",
    "df_a2.columns = df_a2.columns.str.strip()\n",
    "\n",
    "# --- Step 1.2: Rename Columns if Needed ---\n",
    "# For Annotator 1:\n",
    "if 'Argument' not in df_a1.columns and 'Arguments' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Arguments': 'Argument'}, inplace=True)\n",
    "if 'Argument2' not in df_a1.columns and 'Arguments2' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Arguments2': 'Argument2'}, inplace=True)\n",
    "if 'Sense' not in df_a1.columns and 'Senses' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Senses': 'Sense'}, inplace=True)\n",
    "if 'Sense2' not in df_a1.columns and 'Senses2' in df_a1.columns:\n",
    "    df_a1.rename(columns={'Senses2': 'Sense2'}, inplace=True)\n",
    "\n",
    "# For Annotator 2:\n",
    "if 'Argument' not in df_a2.columns and 'Arguments' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Arguments': 'Argument'}, inplace=True)\n",
    "if 'Argument2' not in df_a2.columns and 'Arguments2' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Arguments2': 'Argument2'}, inplace=True)\n",
    "if 'Sense' not in df_a2.columns and 'Senses' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Senses': 'Sense'}, inplace=True)\n",
    "if 'Sense2' not in df_a2.columns and 'Senses2' in df_a2.columns:\n",
    "    df_a2.rename(columns={'Senses2': 'Sense2'}, inplace=True)\n",
    "\n",
    "# --- Step 1.3: (Optional) Preserve Order from Annotator1 ---\n",
    "df_a1['order'] = df_a1.index\n",
    "\n",
    "# --- Step 2: Reshape Each Annotator's Data to Long Format ---\n",
    "df_a1_long = pd.DataFrame({\n",
    "    \"Argument\": pd.concat([df_a1[\"Argument\"], df_a1[\"Argument2\"]], ignore_index=True),\n",
    "    \"Sense_a1\": pd.concat([df_a1[\"Sense\"], df_a1[\"Sense2\"]], ignore_index=True)\n",
    "})\n",
    "df_a2_long = pd.DataFrame({\n",
    "    \"Argument\": pd.concat([df_a2[\"Argument\"], df_a2[\"Argument2\"]], ignore_index=True),\n",
    "    \"Sense_a2\": pd.concat([df_a2[\"Sense\"], df_a2[\"Sense2\"]], ignore_index=True)\n",
    "})\n",
    "\n",
    "# --- Step 2.1: Remove blank or missing Argument entries before merging ---\n",
    "df_a1_long = df_a1_long[df_a1_long[\"Argument\"].notna() & df_a1_long[\"Argument\"].str.strip().ne(\"\")]\n",
    "df_a2_long = df_a2_long[df_a2_long[\"Argument\"].notna() & df_a2_long[\"Argument\"].str.strip().ne(\"\")]\n",
    "\n",
    "# --- Step 3: Merge the Two Long DataFrames on \"Argument\" ---\n",
    "merged_df = pd.merge(df_a1_long, df_a2_long, on=\"Argument\", how=\"outer\", sort=False)\n",
    "\n",
    "# --- Step 4: Process Missing Values ---\n",
    "merged_df[\"Sense_a1\"] = merged_df[\"Sense_a1\"].fillna(\"N/A\")\n",
    "merged_df[\"Sense_a2\"] = merged_df[\"Sense_a2\"].fillna(\"N/A\")\n",
    "\n",
    "# Remove rows where both annotations are \"N/A\"\n",
    "merged_df = merged_df[~((merged_df[\"Sense_a1\"] == \"N/A\") & (merged_df[\"Sense_a2\"] == \"N/A\"))]\n",
    "\n",
    "# --- Step 5: Compute Row-Level Agreement ---\n",
    "def compute_agreement(row):\n",
    "    s1 = row[\"Sense_a1\"].lower().strip()\n",
    "    s2 = row[\"Sense_a2\"].lower().strip()\n",
    "    if s1 == \"n/a\" or s2 == \"n/a\":\n",
    "        return 0\n",
    "    return 1 if s1 == s2 else 0\n",
    "\n",
    "merged_df[\"Agreement\"] = merged_df.apply(compute_agreement, axis=1)\n",
    "\n",
    "# --- Step 6: Compute Global Metrics ---\n",
    "A1_inter_A2 = merged_df['Agreement'].sum()\n",
    "A1_union_A2 = len(merged_df)\n",
    "accuracy = A1_inter_A2 / A1_union_A2 if A1_union_A2 > 0 else 0\n",
    "\n",
    "precision = A1_inter_A2 / merged_df[merged_df['Sense_a1'] != \"N/A\"].shape[0] if merged_df['Sense_a1'].ne(\"N/A\").any() else 0\n",
    "recall = A1_inter_A2 / merged_df[merged_df['Sense_a2'] != \"N/A\"].shape[0] if merged_df['Sense_a2'].ne(\"N/A\").any() else 0\n",
    "f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# --- Step 7: Print Results ---\n",
    "print(\"Global Agreement Metrics:\")\n",
    "print(f\"  Overall Agreement (row-level): {merged_df['Agreement'].mean():.2f}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}\")\n",
    "print(f\"  Precision: {precision:.2f}\")\n",
    "print(f\"  Recall: {recall:.2f}\")\n",
    "print(f\"  F1 Score: {f1:.2f}\")\n",
    "\n",
    "# --- Step 8: Save the Final Merged Comparison to Excel ---\n",
    "output_filename = \"Results/A2 VS FINAL_RV_Plumbing.xlsx\"\n",
    "merged_df.to_excel(output_filename, index=False)\n",
    "print(f\"Comparison results saved to: '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7bdd1c-4b04-4f34-8369-19cfff2cf2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required columns ['Sense', 'Explicit?', 'Arguments'] not all found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_spans(span_str):\n",
    "    \"\"\"Parse span strings like '1', '2-7', '10-11' into a list of integers.\"\"\"\n",
    "    if pd.isna(span_str) or span_str == '':\n",
    "        return []\n",
    "    spans = []\n",
    "    span_str = span_str.replace('Arg1(', '').replace('Arg2(', '').replace(')', '')\n",
    "    parts = span_str.split(',')\n",
    "    for part in parts:\n",
    "        part = part.strip()\n",
    "        if '-' in part:\n",
    "            try:\n",
    "                start, end = map(int, part.split('-'))\n",
    "                spans.extend(range(start, end + 1))\n",
    "            except ValueError:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                spans.append(int(part))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return sorted(set(spans))\n",
    "\n",
    "def is_nonadjacent(arg1_spans, arg2_spans):\n",
    "    \"\"\"Check if Arg1 and Arg2 spans are nonadjacent (gap or non-consecutive).\"\"\"\n",
    "    if not arg1_spans or not arg2_spans:\n",
    "        return False\n",
    "    all_spans = sorted(set(arg1_spans + arg2_spans))\n",
    "    arg1_max, arg2_min = max(arg1_spans), min(arg2_spans)\n",
    "    arg2_max, arg1_min = max(arg2_spans), min(arg1_spans)\n",
    "    return (arg2_min > arg1_max + 1) or (arg1_min > arg2_max + 1)\n",
    "\n",
    "def count_spans(arg_spans):\n",
    "    \"\"\"Count number of spans in an argument.\"\"\"\n",
    "    return len(arg_spans)\n",
    "\n",
    "def parse_discourse_excel(file_path):\n",
    "    # Read Excel file\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_cols = ['Sense', 'Explicit?', 'Arguments']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        print(f\"Required columns {required_cols} not all found.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize counters\n",
    "    implicit_count = 0\n",
    "    explicit_count = 0\n",
    "    nonadjacent_rows = []\n",
    "    compound_rows = []\n",
    "    long_span_rows = []\n",
    "\n",
    "    # Process each row\n",
    "    for idx, row in df.iterrows():\n",
    "        # Implicit/Explicit for Sense\n",
    "        explicit = str(row.get('Explicit?', '')).strip().lower()\n",
    "        if explicit in ['implicit', ''] or 'altlex' in explicit:\n",
    "            if explicit:  # Only count non-empty cells\n",
    "                implicit_count += 1\n",
    "        elif explicit and explicit != 'nan':\n",
    "            explicit_count += 1\n",
    "\n",
    "        # Implicit/Explicit for Sense2\n",
    "        explicit2 = str(row.get('Explicit?.1', '')).strip().lower()\n",
    "        if explicit2 in ['implicit', ''] or 'altlex' in explicit2:\n",
    "            if explicit2:  # Only count non-empty cells\n",
    "                implicit_count += 1\n",
    "        elif explicit2 and explicit2 != 'nan':\n",
    "            explicit_count += 1\n",
    "\n",
    "        # Nonadjacent spans\n",
    "        args = str(row.get('Arguments', ''))\n",
    "        arg2_extra = str(row.get('Argument2', ''))\n",
    "        arg1_match = re.search(r'Arg1\\((.*?)\\)', args)\n",
    "        arg2_match = re.search(r'Arg2\\((.*?)\\)', args)\n",
    "        arg1_spans = parse_spans(arg1_match.group(1) if arg1_match else '')\n",
    "        arg2_spans = parse_spans(arg2_match.group(1) if arg2_match else '')\n",
    "        arg2_extra_match = re.search(r'Arg2\\((.*?)\\)', arg2_extra)\n",
    "        if arg2_extra_match:\n",
    "            arg2_spans.extend(parse_spans(arg2_extra_match.group(1)))\n",
    "            arg2_spans = sorted(set(arg2_spans))\n",
    "        arg1_extra_match = re.search(r'Arg1\\((.*?)\\)', arg2_extra)\n",
    "        if arg1_extra_match:\n",
    "            arg1_spans.extend(parse_spans(arg1_extra_match.group(1)))\n",
    "            arg1_spans = sorted(set(arg1_spans))\n",
    "        if is_nonadjacent(arg1_spans, arg2_spans):\n",
    "            nonadjacent_rows.append(row.get('No.', idx + 1))\n",
    "\n",
    "        # Compound senses\n",
    "        sense = row.get('Sense', '')\n",
    "        sense2 = row.get('Sense2', '')\n",
    "        if pd.notna(sense2) and sense2 != '':\n",
    "            compound_rows.append(row.get('No.', idx + 1))\n",
    "\n",
    "        # Long spans\n",
    "        if count_spans(arg1_spans) >= 3 or count_spans(arg2_spans) >= 3:\n",
    "            long_span_rows.append(row.get('No.', idx + 1))\n",
    "\n",
    "    # Remove duplicates\n",
    "    nonadjacent_rows = sorted(set(nonadjacent_rows))\n",
    "    compound_rows = sorted(set(compound_rows))\n",
    "    long_span_rows = sorted(set(long_span_rows))\n",
    "\n",
    "    # Compile results\n",
    "    results = {\n",
    "        'Implicit Relations': implicit_count,\n",
    "        'Explicit Relations': explicit_count,\n",
    "        'Nonadjacent Spans': len(nonadjacent_rows),\n",
    "        'Nonadjacent Rows': nonadjacent_rows,\n",
    "        'Compound Senses': len(compound_rows),\n",
    "        'Compound Rows': compound_rows,\n",
    "        'Long Spans': len(long_span_rows),\n",
    "        'Long Span Rows': long_span_rows\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Replace with your Excel file path\n",
    "    file_path = 'Final Annotation of RV Plumbing.xlsx'\n",
    "    \n",
    "    results = parse_discourse_excel(file_path)\n",
    "    if results:\n",
    "        print(\"\\nDiscourse Analysis Results:\")\n",
    "        print(f\"Implicit Relations: {results['Implicit Relations']}\")\n",
    "        print(f\"Explicit Relations: {results['Explicit Relations']}\")\n",
    "        print(f\"Nonadjacent Spans: {results['Nonadjacent Spans']} (Rows: {results['Nonadjacent Rows']})\")\n",
    "        print(f\"Compound Senses: {results['Compound Senses']} (Rows: {results['Compound Rows']})\")\n",
    "        print(f\"Long Spans: {results['Long Spans']} (Rows: {results['Long Span Rows']})\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        summary_df = pd.DataFrame({\n",
    "            'Metric': ['Implicit Relations', 'Explicit Relations', 'Nonadjacent Spans', 'Compound Senses', 'Long Spans'],\n",
    "            'Count': [results['Implicit Relations'], results['Explicit Relations'], \n",
    "                      results['Nonadjacent Spans'], results['Compound Senses'], results['Long Spans']],\n",
    "            'Rows': ['', '', str(results['Nonadjacent Rows']), str(results['Compound Rows']), str(results['Long Span Rows'])]\n",
    "        })\n",
    "        summary_df.to_csv('discourse_metrics.csv', index=False)\n",
    "       # print(\"\\nResults saved to 'discourse_metrics.csv'\")\n",
    "        \n",
    "        # Save to Excel\n",
    "        summary_df.to_excel('discourse_metrics.xlsx', index=False, engine='openpyxl')\n",
    "        print(\"Results also saved to 'discourse_metrics.xlsx'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9b4a7-2b6f-4cc8-ad77-5362ae1d4462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
